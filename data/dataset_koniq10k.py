""" import os
import pandas as pd
import torch
import numpy as np
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image

class KONIQ10KDataset(Dataset):
    def __init__(self, root: str, phase: str = "all", crop_size: int = 224):
        super().__init__()
        self.root = root
        self.phase = phase.strip().lower()  # ðŸ”¹ ê³µë°± ì œê±° í›„ ì†Œë¬¸ìžë¡œ ë³€í™˜
        self.crop_size = crop_size

        # âœ… CSV íŒŒì¼ ë¡œë“œ
        scores_csv_path = os.path.join(self.root, "meta_info_KonIQ10kDataset.csv")
        if not os.path.isfile(scores_csv_path):
            raise FileNotFoundError(f"CSV íŒŒì¼ì´ {scores_csv_path} ê²½ë¡œì— ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        scores_csv = pd.read_csv(scores_csv_path)

        self.images = scores_csv["image_name"].values
        self.mos = scores_csv["MOS"].astype(float).values  # âœ… MOS ê°’ì„ floatìœ¼ë¡œ ë³€í™˜

        # âœ… set ì»¬ëŸ¼ ë³€í™˜ (ì†Œë¬¸ìžë¡œ ë³€í™˜ í›„ 'training' â†’ 'train', 'validation' â†’ 'val')
        self.sets = scores_csv["set"].astype(str).str.strip().str.lower().replace({
            "training": "train",
            "validation": "val"
        })

        # âœ… MOS ê°’ ê²€ì‚¬ ë° ì •ë¦¬ (NaN/Inf ì²˜ë¦¬)
        print(f"[Check] ì´ MOS ê°’ ê°œìˆ˜: {len(self.mos)}")
        print(f"[Check] NaN ê°œìˆ˜: {np.isnan(self.mos).sum()}, Inf ê°œìˆ˜: {np.isinf(self.mos).sum()}")

        if np.isnan(self.mos).sum() > 0 or np.isinf(self.mos).sum() > 0:
            self.mos = np.nan_to_num(self.mos, nan=0.5, posinf=1.0, neginf=0.0)  # NaNì„ 0.5ë¡œ ëŒ€ì²´

        # âœ… MOS ê°’ ì •ê·œí™” (0~1 ë²”ìœ„)
        mos_min = np.min(self.mos)
        mos_max = np.max(self.mos)
        if mos_max - mos_min == 0:
            raise ValueError("[Error] MOS ê°’ì˜ ìµœì†Œê°’ê³¼ ìµœëŒ€ê°’ì´ ë™ì¼í•˜ì—¬ ì •ê·œí™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        self.mos = (self.mos - mos_min) / (mos_max - mos_min)
        print(f"[Check] MOS ìµœì†Œê°’: {np.min(self.mos)}, ìµœëŒ€ê°’: {np.max(self.mos)}")

        # âœ… ë°ì´í„° í•„í„°ë§ (train/val/test ì„ íƒ)
        if self.phase != "all":
            indices = [i for i, s in enumerate(self.sets) if s == self.phase]  # âœ… ë¹„êµ ë°©ì‹ ìˆ˜ì •

            if len(indices) == 0:
                print(f"[Error] '{self.phase}'ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 'set' ì»¬ëŸ¼ ê°’ í™•ì¸ í•„ìš”.")
                print(f"âœ… set ì»¬ëŸ¼ ìœ ë‹ˆí¬ ê°’: {self.sets.unique()}")  # ìœ ë‹ˆí¬í•œ ê°’ ì¶œë ¥
                raise ValueError(f"[Error] '{self.phase}'ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            self.images = self.images[indices]
            self.mos = self.mos[indices]

        # âœ… ì´ë¯¸ì§€ ê²½ë¡œ ìƒì„±
        self.image_paths = [os.path.join(self.root, "1024x768", img) for img in self.images]

        print(f"[Debug] Phase: {self.phase}")
        print(f"[Debug] Total Records: {len(self.image_paths)}")  # âœ… ë°ì´í„° ê°œìˆ˜ í™•ì¸

    def transform(self, image: Image) -> torch.Tensor:
        return transforms.Compose([
            transforms.Resize((self.crop_size, self.crop_size)),
            transforms.ToTensor(),
        ])(image)

    def __getitem__(self, index: int):
        image_path = self.image_paths[index]
        mos = self.mos[index]

        try:
            img_A = Image.open(image_path).convert("RGB")  # âœ… ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
        except Exception as e:
            print(f"[Error] ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}: {e}")
            return None

        img_A_transformed = self.transform(img_A)

        return {
            "img_A": img_A_transformed,
            "mos": torch.tensor(mos, dtype=torch.float32),
        }

    def __len__(self):
        return len(self.image_paths)


# âœ… ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    dataset_path = "E:/ARNIQA - SE - mix/ARNIQA/dataset/KONIQ10K"

    dataset = KONIQ10KDataset(root=dataset_path, phase="train", crop_size=224)
    dataloader = DataLoader(dataset, batch_size=4, shuffle=True)

    print(f"Dataset size: {len(dataset)}")

    # âœ… ì²« ë²ˆì§¸ ë°°ì¹˜ í™•ì¸
    sample_batch = next(iter(dataloader))
    print(f"Sample Image Shape: {sample_batch['img_A'].shape}")
    print(f"Sample MOS Scores: {sample_batch['mos']}")
 """

import os
import pandas as pd
import torch
import numpy as np
from torch.utils.data import Dataset
from torchvision import transforms
from PIL import Image

import os
import pandas as pd

class KONIQ10KDataset(Dataset):
    def __init__(self, root: str, phase: str = "all", crop_size: int = 224):
        super().__init__()
        self.root = root
        self.phase = phase.strip().lower()
        self.crop_size = crop_size

        # âœ… CSV íŒŒì¼ ê²½ë¡œ ë””ë²„ê¹… ì¶œë ¥
        scores_csv_path = os.path.join(self.root, "meta_info_KonIQ10kDataset.csv")
        print(f"[DEBUG] Checking CSV Path: {scores_csv_path}")

        if not os.path.isfile(scores_csv_path):
            raise FileNotFoundError(f"âŒ CSV íŒŒì¼ì´ {scores_csv_path} ê²½ë¡œì— ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
                                    f"íŒŒì¼ì´ ì¡´ìž¬í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”!")

        scores_csv = pd.read_csv(scores_csv_path)


        self.images = scores_csv["image_name"].values
        self.mos = scores_csv["MOS"].astype(float).values

        # âœ… MOS ê°’ ì •ê·œí™”
        self.mos = (self.mos - np.min(self.mos)) / (np.max(self.mos) - np.min(self.mos))

        # âœ… ì´ë¯¸ì§€ ê²½ë¡œ ìƒì„±
        self.image_paths = [os.path.join(self.root, "1024x768", img) for img in self.images]

    def transform(self, image: Image) -> torch.Tensor:
        return transforms.Compose([
            transforms.Resize((self.crop_size, self.crop_size)),
            transforms.ToTensor(),
        ])(image)

    def __getitem__(self, index: int):
        image_path = self.image_paths[index]
        img_A = Image.open(image_path).convert("RGB")
        img_A_transformed = self.transform(img_A)

        return {
            "index": index,  # âœ… ì¶”ê°€
            "img_A": img_A_transformed,
            "mos": torch.tensor(self.mos[index], dtype=torch.float32),
        }

    def __len__(self):
        return len(self.image_paths)
